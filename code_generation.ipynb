{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fab6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5dba8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils\n",
    "u = Utils(user_id=1, file_id=1)\n",
    "response = u.response\n",
    "read_code = u.read_code\n",
    "write_code = u.write_code\n",
    "update_prompt = u.update_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b313ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = '''Instruction: You are a code generation assistant for machine learning problem. \n",
    "Code is in Python. \n",
    "Please import all libraries. \n",
    "Please follow carefully each sentence in the prompt after the \"Q:\".\n",
    "'''\n",
    "\n",
    "problem = '''Problem:\n",
    "\n",
    "This dataset of credit risk consists of 20 features of the customers.\n",
    "It could be used to predict if the customer could be given credit.\n",
    "column name       column type\n",
    "checking_status            object\n",
    "duration                  float64\n",
    "credit_history             object\n",
    "purpose                    object\n",
    "credit_amount             float64\n",
    "savings_status             object\n",
    "employment                 object\n",
    "installment_commitment    float64\n",
    "personal_status            object\n",
    "other_parties              object\n",
    "residence_since           float64\n",
    "property_magnitude         object\n",
    "age                       float64\n",
    "other_payment_plans        object\n",
    "housing                    object\n",
    "existing_credits          float64\n",
    "job                        object\n",
    "num_dependents            float64\n",
    "own_telephone              object\n",
    "foreign_worker             object\n",
    "class                      object\n",
    "target variable is 'class'\n",
    "'''\n",
    "\n",
    "ans = '''\n",
    "A:\n",
    "<code>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b8ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/subhranilmondal12/data-visualization-mlmodel-withcross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c040ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = [None] * 100\n",
    "nb_file = 'credit_code.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08682cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Import'\n",
    "prompt_what = 'csv data file'\n",
    "prompt_how = '''from the path 'credit_customers.csv' to a variable named 'credit' '''\n",
    "prompt = 'Q:{} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = ''\n",
    "prompt_source = ''\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, -1)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3d0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "credit = pd.read_csv('credit_customers.csv')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9621d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_prompt(prompt_list, 0, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ca430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Show'\n",
    "prompt_what = 'unique values'\n",
    "prompt_how = '''of each column. Print the number of unique values.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '0'\n",
    "prompt_source = ''\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 0)\n",
    "    \n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a7f3168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for col in credit.columns:\n",
      "    print('Unique values of {}: {}'.format(col, credit[col].unique()))\n",
      "    print('Number of unique values of {}: {}'.format(col, len(credit[col].unique())))\n",
      "    print('\\n')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 1)\n",
    "\n",
    "update_prompt(prompt_list, 1, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46118dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_how = prompt_list[1]['prompt_how'] + '''\n",
    "Show the name of each column in the loop. Only print for object type columns.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '0'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 0)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8876b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for col in credit.columns:\n",
      "    if credit[col].dtype == 'object':\n",
      "        print('Column Name:', col)\n",
      "        print('Unique Values:', credit[col].unique())\n",
      "        print('Number of Unique Values:', len(credit[col].unique()))\n",
      "        print('\\n')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 1)\n",
    "\n",
    "update_prompt(prompt_list, 1, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79bb7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Split'\n",
    "prompt_what = ''' column 'personal_status' '''\n",
    "prompt_how= '''\n",
    "into 2 columns named 'gender' and 'marital_status'. Drop old column\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '0'\n",
    "prompt_source = 'Human Knowledge'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 1)\n",
    "    \n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1353f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Split 'personal_status' into 2 columns\n",
      "credit[['gender', 'marital_status']] = credit['personal_status'].str.split(' ', expand=True)\n",
      "\n",
      "# Drop old column\n",
      "credit.drop('personal_status', axis=1, inplace=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 2)\n",
    "\n",
    "update_prompt(prompt_list, 2, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "403c5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Visualize'\n",
    "prompt_what = 'categorical features'\n",
    "prompt_how = '''\n",
    "by Countplot. Write each plot as a subplot using a loop. \n",
    "Add the title to the plot as the feature name + '_count'. Please Import all libraries.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '0'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 2)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46049905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Visualize categorical features by Countplot\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "fig, ax = plt.subplots(nrows=5, ncols=4, figsize=(20,20))\n",
      "\n",
      "for i, col in enumerate(credit.columns):\n",
      "    if credit[col].dtype == 'object':\n",
      "        sns.countplot(x=col, data=credit, ax=ax[i//4, i%4])\n",
      "        ax[i//4, i%4].set_title(col + '_count')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 3)\n",
    "\n",
    "update_prompt(prompt_list, 3, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb9162c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_how = prompt_list[3]['prompt'] + '''\n",
    "Adjust spacing between subplots. List the number of categorical features first.\n",
    "Please please Import all libraries.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '0'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 2)\n",
    "    \n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d8829ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# List of categorical features\n",
      "cat_features = ['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', 'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker', 'gender', 'marital_status']\n",
      "\n",
      "# Visualize categorical features\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
      "\n",
      "for i, ax in enumerate(fig.axes):\n",
      "    if i < len(cat_features):\n",
      "        sns.countplot(x=cat_features[i], data=credit, ax=ax)\n",
      "        ax.set_title(cat_features[i] + '_count')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 3)\n",
    "    \n",
    "update_prompt(prompt_list, 3, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cd3f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Plot'\n",
    "prompt_what = 'categorical features'\n",
    "prompt_how = '''by Pieplot.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '3'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 3)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n",
    "#prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33fd2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Pieplot\n",
      "fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
      "\n",
      "for i, ax in enumerate(fig.axes):\n",
      "    if i < len(cat_features):\n",
      "        credit[cat_features[i]].value_counts().plot.pie(autopct='%1.1f%%', ax=ax)\n",
      "        ax.set_title(cat_features[i] + '_pieplot')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 4)\n",
    "    \n",
    "update_prompt(prompt_list, 4, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "444055a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Plot'\n",
    "prompt_what = 'Numerical Features'\n",
    "prompt_how = '''by KDEplot. Please use the number of subplots equals to the number of numerical features.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '3'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 4)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a23f2b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# List of numerical features\n",
      "num_features = ['duration', 'credit_amount', 'installment_commitment', 'residence_since', 'age', 'existing_credits', 'num_dependents']\n",
      "\n",
      "# KDEplot\n",
      "fig, ax = plt.subplots(4, 2, figsize=(20, 20))\n",
      "\n",
      "for i, ax in enumerate(fig.axes):\n",
      "    if i < len(num_features):\n",
      "        sns.kdeplot(credit[num_features[i]], ax=ax)\n",
      "        ax.set_title(num_features[i] + '_KDEplot')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 5)\n",
    "    \n",
    "update_prompt(prompt_list, 5, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cc28bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Plot'\n",
    "prompt_what = 'Categorical Features against the target feature'\n",
    "prompt_how = '''by Countplot.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '3'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 5)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43886779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Countplot\n",
      "fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
      "\n",
      "for i, ax in enumerate(fig.axes):\n",
      "    if i < len(cat_features):\n",
      "        sns.countplot(x=cat_features[i], hue='class', data=credit, ax=ax)\n",
      "        ax.set_title(cat_features[i] + '_countplot')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 6)\n",
    "    \n",
    "update_prompt(prompt_list, 6, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f3d48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Encode'\n",
    "prompt_what = 'categorical feature including the target'\n",
    "prompt_how= '''by Label Encoding\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '6'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 6)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50bc7c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Label Encoding\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "le = LabelEncoder()\n",
      "\n",
      "for col in cat_features:\n",
      "    credit[col] = le.fit_transform(credit[col])\n",
      "\n",
      "# Target Encoding\n",
      "credit['class'] = le.fit_transform(credit['class'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 7)\n",
    "    \n",
    "update_prompt(prompt_list, 7, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0db782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Scale'\n",
    "prompt_what = 'numerical feature'\n",
    "prompt_how = '''by MinMaxScaler\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '7'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 7)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a38c5f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Scale numerical feature by MinMaxScaler\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "for col in num_features:\n",
      "    credit[col] = scaler.fit_transform(credit[[col]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 8)\n",
    "    \n",
    "update_prompt(prompt_list, 8, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20547284",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Split'\n",
    "prompt_what = 'training and testing data.'\n",
    "prompt_how = '''Test size = 0.3. Random state = 1.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '8'\n",
    "prompt_source = ''\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 8)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86f3429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Split training and testing data\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "X = credit.drop('class', axis=1)\n",
      "y = credit['class']\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 9)\n",
    "    \n",
    "update_prompt(prompt_list, 9, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7a33983",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Train'\n",
    "prompt_what = 'Logistic Regression model'\n",
    "prompt_how = '''. Show accuracy, f1-score, confusion matrix.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '9'\n",
    "prompt_source = ''\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 9)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5282cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Train Logistic Regression model\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "logreg = LogisticRegression()\n",
      "logreg.fit(X_train, y_train)\n",
      "\n",
      "# Show accuracy, f1-score, confusion matrix\n",
      "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
      "\n",
      "y_pred = logreg.predict(X_test)\n",
      "\n",
      "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
      "print('F1-Score:', f1_score(y_test, y_pred))\n",
      "print('Confusion Matrix:')\n",
      "print(confusion_matrix(y_test, y_pred))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 10)\n",
    "    \n",
    "update_prompt(prompt_list, 10, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb003d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Train'\n",
    "prompt_what = 'Naive Bayes Model'\n",
    "prompt_how = '''\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '9'\n",
    "prompt_source = ''\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 10)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95b5e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Train Naive Bayes Model\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "nb = GaussianNB()\n",
      "nb.fit(X_train, y_train)\n",
      "\n",
      "# Show accuracy, f1-score, confusion matrix\n",
      "y_pred = nb.predict(X_test)\n",
      "\n",
      "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
      "print('F1-Score:', f1_score(y_test, y_pred))\n",
      "print('Confusion Matrix:')\n",
      "print(confusion_matrix(y_test, y_pred))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 11)\n",
    "    \n",
    "update_prompt(prompt_list, 11, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52be73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Plot'\n",
    "prompt_what = 'model comparison by f1-score'\n",
    "prompt_how = '''by Boxplot. Use previous trained models.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '11'\n",
    "prompt_source = ''\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 11)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9145a527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Plot model comparison by f1-score by Boxplot\n",
      "import numpy as np\n",
      "\n",
      "models = ['Logistic Regression', 'Naive Bayes']\n",
      "f1_scores = [f1_score(y_test, logreg.predict(X_test)), f1_score(y_test, nb.predict(X_test))]\n",
      "\n",
      "plt.boxplot(f1_scores, labels=models)\n",
      "plt.title('Model Comparison by F1-Score')\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 12)\n",
    "    \n",
    "update_prompt(prompt_list, 12, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11401a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5765ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694157e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f90b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11a6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in prompt_list:\n",
    "    if a is not None:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "nb_code = json.load(open('credit_code.ipynb'))\n",
    "nb_code['cells'][0]['outputs']['text'] = ''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
