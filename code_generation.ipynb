{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fab6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5dba8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils\n",
    "u = Utils(user_id=1, file_id=1)\n",
    "response = u.response\n",
    "read_code = u.read_code\n",
    "write_code = u.write_code\n",
    "update_prompt = u.update_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b313ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = '''Instruction: You are a code generation assistant for machine learning problem. \n",
    "Code is in Python. \n",
    "Please import all libraries. \n",
    "Please follow carefully each sentence in the prompt after the \"Q:\".\n",
    "'''\n",
    "\n",
    "problem = '''Problem:\n",
    "\n",
    "This dataset of credit risk consists of 20 features of the customers.\n",
    "It could be used to predict if the customer could be given credit.\n",
    "column name       column type\n",
    "checking_status            object\n",
    "duration                  float64\n",
    "credit_history             object\n",
    "purpose                    object\n",
    "credit_amount             float64\n",
    "savings_status             object\n",
    "employment                 object\n",
    "installment_commitment    float64\n",
    "personal_status            object\n",
    "other_parties              object\n",
    "residence_since           float64\n",
    "property_magnitude         object\n",
    "age                       float64\n",
    "other_payment_plans        object\n",
    "housing                    object\n",
    "existing_credits          float64\n",
    "job                        object\n",
    "num_dependents            float64\n",
    "own_telephone              object\n",
    "foreign_worker             object\n",
    "class                      object\n",
    "target variable is 'class'\n",
    "'''\n",
    "\n",
    "ans = '''\n",
    "A:\n",
    "<code>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b8ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/subhranilmondal12/data-visualization-mlmodel-withcross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c040ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = [None] * 100\n",
    "nb_file = 'credit_code.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08682cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Import'\n",
    "prompt_what = 'csv data file'\n",
    "prompt_how = '''from the path 'credit_customers.csv' to a variable named 'credit' '''\n",
    "prompt = 'Q:{} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = ''\n",
    "prompt_source = ''\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, -1)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3d0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "credit = pd.read_csv('credit_customers.csv')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9621d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_prompt(prompt_list, 0, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28ca430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Show'\n",
    "prompt_what = 'unique values'\n",
    "prompt_how = '''of each column. Print the number of unique values.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '0'\n",
    "prompt_source = ''\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 0)\n",
    "    \n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a7f3168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for col in credit.columns:\n",
      "    print('Unique values of {}: {}'.format(col, credit[col].unique()))\n",
      "    print('Number of unique values of {}: {}'.format(col, len(credit[col].unique())))\n",
      "    print('\\n')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 1)\n",
    "\n",
    "update_prompt(prompt_list, 1, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46118dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_how = prompt_list[1]['prompt_how'] + '''\n",
    "Show the name of each column in the loop. Only print for object type columns.\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '0'\n",
    "prompt_source = 'Metadata'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 0)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8876b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for col in credit.columns:\n",
      "    if credit[col].dtype == 'object':\n",
      "        print('Column Name:', col)\n",
      "        print('Unique Values:', credit[col].unique())\n",
      "        print('Number of Unique Values:', len(credit[col].unique()))\n",
      "        print('\\n')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 1)\n",
    "\n",
    "update_prompt(prompt_list, 1, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79bb7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_task = 'Split'\n",
    "prompt_what = ''' column 'personal_status' '''\n",
    "prompt_how= '''\n",
    "into 2 columns named 'gender' and 'marital_status'. Drop old column\n",
    "'''\n",
    "prompt = 'Q: {} {} {}'.format(prompt_task, prompt_what, prompt_how)\n",
    "pre_prompt_idx = '0'\n",
    "prompt_source = 'Human Knowledge'\n",
    "data_source = ''\n",
    "\n",
    "code = read_code(prompt_list, 1)\n",
    "    \n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1353f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Split 'personal_status' into 2 columns\n",
      "credit[['gender', 'marital_status']] = credit['personal_status'].str.split(' ', expand=True)\n",
      "\n",
      "# Drop old column\n",
      "credit.drop('personal_status', axis=1, inplace=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(nb_file, code, out, 2)\n",
    "\n",
    "update_prompt(prompt_list, 2, instruction, problem, ans, prompt_task, prompt_what, prompt_how, out, \n",
    "              pre_prompt_idx, prompt_source, data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "403c5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type = 'Metadata'\n",
    "prompt = '''\n",
    "Q: Visualizing Categorical Features by Countplot. Write each plot as a subplot using a loop. \n",
    "Add the title to the plot as the feature name + '_count'. Please Import all libraries.\n",
    "'''\n",
    "pre_prompt_idx = 0\n",
    "\n",
    "code = read_code(prompt_list, 2)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "46049905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Visualizing Categorical Features by Countplot\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "# Set the figure size\n",
      "plt.figure(figsize=(20,20))\n",
      "\n",
      "# Loop through the categorical columns\n",
      "for i, col in enumerate(credit.select_dtypes(include='object').columns):\n",
      "    plt.subplot(5, 4, i+1)\n",
      "    sns.countplot(x=col, data=credit)\n",
      "    plt.title(f\"{col}_count\")\n",
      "\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 3)\n",
    "\n",
    "update_prompt(prompt_list, 3, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bb9162c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_list[3]['prompt'] + '''\n",
    "Adjust spacing between subplots. List the number of categorical features first.\n",
    "Please please Import all libraries.\n",
    "'''\n",
    "pre_prompt_idx = 0\n",
    "prompt_type = 'Metadata'\n",
    "\n",
    "code = read_code(prompt_list, 2)\n",
    "    \n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0d8829ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Get the list of categorical features\n",
      "cat_features = credit.select_dtypes(include='object').columns.tolist()\n",
      "\n",
      "# Visualize the categorical features\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "fig, ax = plt.subplots(nrows=len(cat_features), ncols=1, figsize=(10,20))\n",
      "\n",
      "for i, feature in enumerate(cat_features):\n",
      "    sns.countplot(x=feature, data=credit, ax=ax[i])\n",
      "    ax[i].set_title(f\"{feature}_count\")\n",
      "    ax[i].set_xlabel(feature)\n",
      "    ax[i].set_ylabel('Count')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "(\"\\nQ: Visualizing Categorical Features by Countplot. Write each plot as a subplot using a loop. \\nAdd the title to the plot as the feature name + '_count'. Please Import all libraries.\\n\\nAdjust spacing between subplots. List the number of categorical features first.\\nPlease please Import all libraries.\\n\\nAdjust spacing between subplots. List the number of categorical features first.\\nPlease please Import all libraries.\\n\", '\\n# Get the list of categorical features\\ncat_features = credit.select_dtypes(include=\\'object\\').columns.tolist()\\n\\n# Visualize the categorical features\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\nfig, ax = plt.subplots(nrows=len(cat_features), ncols=1, figsize=(10,20))\\n\\nfor i, feature in enumerate(cat_features):\\n    sns.countplot(x=feature, data=credit, ax=ax[i])\\n    ax[i].set_title(f\"{feature}_count\")\\n    ax[i].set_xlabel(feature)\\n    ax[i].set_ylabel(\\'Count\\')\\n\\nplt.tight_layout()\\nplt.show()\\n', 'Metadata', '', '0', 1, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 3)\n",
    "    \n",
    "update_prompt(prompt_list, 3, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1cd3f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type = 'Metadata'\n",
    "prompt = '''Q: Visualizing Categorical Features by Pieplot. Please List categorical features first. Please use subplots.\n",
    "'''\n",
    "pre_prompt_idx = 3\n",
    "\n",
    "code = read_code(prompt_list, 3)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "33fd2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Visualizing Categorical Features by Pieplot\n",
      "fig, ax = plt.subplots(nrows=5, ncols=4, figsize=(20,20))\n",
      "\n",
      "row = 0\n",
      "col = 0\n",
      "\n",
      "categorical_features = ['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', 'other_parties', 'property_magnitude', 'other_payment_plans', 'housing', 'job', 'own_telephone', 'foreign_worker', 'gender', 'marital_status']\n",
      "\n",
      "for i, column in enumerate(categorical_features):\n",
      "    if col == 4:\n",
      "        row += 1\n",
      "        col = 0\n",
      "    credit[column].value_counts().plot.pie(ax=ax[row][col], autopct='%1.1f%%')\n",
      "    ax[row][col].set_title(column + '_pieplot')\n",
      "    col += 1\n",
      "\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 4)\n",
    "    \n",
    "update_prompt(prompt_list, 4, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "444055a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type = 'Metadata'\n",
    "prompt = '''Q: Visualizing Numerical Features by KDEplot.\n",
    "Please use the number of subplots equals to the number of numerical features.\n",
    "'''\n",
    "pre_prompt_idx = 3\n",
    "\n",
    "code = read_code(prompt_list, 4)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a23f2b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Visualizing Numerical Features by KDEplot\n",
      "fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(20,20))\n",
      "\n",
      "row = 0\n",
      "col = 0\n",
      "\n",
      "for i, column in enumerate(credit.select_dtypes(include='float64').columns):\n",
      "    if col == 2:\n",
      "        row += 1\n",
      "        col = 0\n",
      "    sns.kdeplot(credit[column], ax=ax[row][col])\n",
      "    ax[row][col].set_title(column + '_kdeplot')\n",
      "    col += 1\n",
      "\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 5)\n",
    "    \n",
    "update_prompt(prompt_list, 5, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5cc28bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type = 'Metadata'\n",
    "prompt = '''Q: Visualizing Categorical Features against the target feature by Countplot.\n",
    "Please add spacing between subplots. Please use the previous list categorical features.\n",
    "'''\n",
    "pre_prompt_idx=3\n",
    "\n",
    "code = read_code(prompt_list, 5)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "43886779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Visualizing Categorical Features against the target feature by Countplot\n",
      "fig, ax = plt.subplots(nrows=5, ncols=4, figsize=(20,20))\n",
      "\n",
      "row = 0\n",
      "col = 0\n",
      "\n",
      "for i, column in enumerate(credit.select_dtypes(include='object').columns):\n",
      "    if col == 4:\n",
      "        row += 1\n",
      "        col = 0\n",
      "    sns.countplot(x=column, hue='class', data=credit, ax=ax[row][col])\n",
      "    ax[row][col].set_title(column + '_count')\n",
      "    col += 1\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 6)\n",
    "    \n",
    "update_prompt(prompt_list, 6, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1f3d48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Q: Label Encoding for categorical feature including the target.\n",
    "'''\n",
    "prompt_type = 'Metadata'\n",
    "pre_prompt_idx = 0\n",
    "\n",
    "code = read_code(prompt_list, 6)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "50bc7c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Label Encoding\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "le = LabelEncoder()\n",
      "\n",
      "for col in credit.select_dtypes(include='object').columns:\n",
      "    credit[col] = le.fit_transform(credit[col])\n",
      "\n",
      "print(credit.head())\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 7)\n",
    "    \n",
    "update_prompt(prompt_list, 7, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e0db782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Q: Data scaling for numerical feature.\n",
    "'''\n",
    "prompt_type = 'Metadata'\n",
    "pre_prompt_idx = 7\n",
    "\n",
    "code = read_code(prompt_list, 7)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a38c5f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Data Scaling\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "scaler = MinMaxScaler()\n",
      "\n",
      "for col in credit.select_dtypes(include=['float64', 'int64']).columns:\n",
      "    credit[col] = scaler.fit_transform(credit[[col]])\n",
      "\n",
      "print(credit.head())\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 8)\n",
    "    \n",
    "update_prompt(prompt_list, 8, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "20547284",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Q: Split training and testing data. Test size = 0.3. Random state = 1.\n",
    "'''\n",
    "prompt_type='Auto'\n",
    "pre_prompt_idx=8\n",
    "\n",
    "code = read_code(prompt_list, 8)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "86f3429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Split training and testing data\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "X = credit.drop('class', axis=1)\n",
      "y = credit['class']\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 9)\n",
    "    \n",
    "update_prompt(prompt_list, 9, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f7a33983",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Q: Logistic Regression model for training. Show accuracy, f1-score, confusion matrix.\n",
    "'''\n",
    "prompt_type='Auto'\n",
    "pre_prompt_idx=9\n",
    "\n",
    "code = read_code(prompt_list, 9)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5282cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Logistic Regression Model\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "logreg = LogisticRegression()\n",
      "logreg.fit(X_train, y_train)\n",
      "\n",
      "# Model Evaluation\n",
      "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
      "\n",
      "y_pred = logreg.predict(X_test)\n",
      "\n",
      "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
      "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
      "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 10)\n",
    "    \n",
    "update_prompt(prompt_list, 10, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fb003d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Q: Naive Bayes Model for training.\n",
    "'''\n",
    "prompt_type = 'Auto'\n",
    "pre_prompt_idx = 9\n",
    "\n",
    "code = read_code(prompt_list, 10)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "95b5e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Naive Bayes Model\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "nb = GaussianNB()\n",
      "nb.fit(X_train, y_train)\n",
      "\n",
      "# Model Evaluation\n",
      "y_pred = nb.predict(X_test)\n",
      "\n",
      "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
      "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
      "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 11)\n",
    "    \n",
    "update_prompt(prompt_list, 11, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "52be73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Q: Boxplot for model comparison by f1-score, logistic regression and naive bayes\n",
    "'''\n",
    "prompt_type = 'Auto'\n",
    "pre_prompt_idx = 11\n",
    "\n",
    "code = read_code(prompt_list, 11)\n",
    "\n",
    "prefix = instruction + problem + prompt + ans + code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9145a527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Boxplot for model comparison by f1-score\n",
      "import numpy as np\n",
      "\n",
      "models = ['Logistic Regression', 'Naive Bayes']\n",
      "f1_scores = [f1_score(y_test, logreg.predict(X_test)), f1_score(y_test, nb.predict(X_test))]\n",
      "\n",
      "x_pos = np.arange(len(models))\n",
      "\n",
      "plt.bar(x_pos, f1_scores, align='center', alpha=0.5)\n",
      "plt.xticks(x_pos, models)\n",
      "plt.ylabel('F1 Score')\n",
      "plt.title('Model Comparison by F1 Score')\n",
      "\n",
      "plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = response(prefix)\n",
    "print(out)\n",
    "code += out\n",
    "write_code(code_file, nb_file, code, out, 12)\n",
    "    \n",
    "update_prompt(prompt_list, 12, instruction, problem, ans, prompt, out, pre_prompt_idx, prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11401a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5765ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694157e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f90b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11a6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in prompt_list:\n",
    "    if a is not None:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "nb_code = json.load(open('credit_code.ipynb'))\n",
    "nb_code['cells'][0]['outputs']['text'] = ''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
