{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "3e86a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "116574a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from config import upload_folder, allowed_extensions, open_api_mode, jupyter_url, openai_key\n",
    "from utils import read_code, response, update_prompt, prompt_list_len, read_codev1, read_output_from_nb, write_code\n",
    "from database import Database\n",
    "\n",
    "# show unlimited pandas\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# show unlimited numpy\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# do not show backtrace in python error\n",
    "import sys\n",
    "sys.tracebacklimit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "65bda4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = [None] * 100\n",
    "\n",
    "instruction1 = '''You are the python code generation for a data science problem.\n",
    "Please generate the next code after \"A: <code>\"\n",
    "'''\n",
    "\n",
    "instruction2 = '''You are the python code generation for a data science problem.\n",
    "Please always generate the full training code given the previous code and the prompt.\n",
    "'''\n",
    "\n",
    "instruction = instruction1\n",
    "method = 1\n",
    "version = 3\n",
    "\n",
    "problem = '''Problem Description:\n",
    "'''\n",
    "\n",
    "ans = '''\n",
    "A:\n",
    "<code>\n",
    "'''\n",
    "\n",
    "data_file = ''\n",
    "nb_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "6322f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_preprocessing(prompt):\n",
    "    dataset_metadata = '\\nDataset Information:\\n'\n",
    "    data_values = '\\nData Values of {}:\\n'\n",
    "    \n",
    "    prompt_support = ''\n",
    "        \n",
    "    if \"@datafile\" in prompt:\n",
    "        prompt = prompt.replace(\"@datafile\", \"\").strip()\n",
    "        prompt_support += 'Data file name: {}.\\n'.format(data_file)\n",
    "        \n",
    "    if \"@metadata\" in prompt:\n",
    "        prompt = prompt.replace(\"@metadata\", \"\").strip()\n",
    "        dataset_metadata += get_dataset_metadata(data_file)\n",
    "        prompt_support += dataset_metadata + '\\n------------\\n'\n",
    "        \n",
    "    if \"@data-values\" in prompt:\n",
    "        instr = prompt[prompt.index(\"@data-values\"):]\n",
    "        prompt = prompt.replace(instr, \"\").strip()\n",
    "        col_name = instr[instr.index(\"/\")+1:]\n",
    "        col_names = [col for col in col_name.split(\",\")]\n",
    "        col_names = ','.join(col_names)\n",
    "        data_values = data_values.format(col_names)\n",
    "        data_values += get_dataset_values(data_file, col_names)\n",
    "        prompt_support += data_values\n",
    "        \n",
    "    return prompt, prompt_support\n",
    "\n",
    "def get_dataset_metadata(data_file):\n",
    "    df = pd.read_csv(data_file)\n",
    "    import io\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    metadata = buf.getvalue()\n",
    "    return metadata\n",
    "\n",
    "def get_dataset_values(data_file, col_name):\n",
    "    df = pd.read_csv(data_file)\n",
    "    # get unique values of col_name\n",
    "    values = sorted(df[col_name].unique())\n",
    "    #values = values[np.random.choice(len(values), min(len(values), 20), replace=False)]\n",
    "    values = values[-10:]\n",
    "    return str(values)\n",
    "\n",
    "\n",
    "def exec_code(code):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "    from contextlib import redirect_stdout\n",
    "    \n",
    "    code = '''{}'''.format(code)\n",
    "\n",
    "    f = StringIO()\n",
    "    error = False\n",
    "    with redirect_stdout(f):\n",
    "        try:\n",
    "            exec(code)\n",
    "            out_value = f.getvalue()\n",
    "        except Exception as e:\n",
    "            error = True\n",
    "            out_value = \"{}: {}\".format(type(e).__name__, e)\n",
    "    \n",
    "    return out_value, error\n",
    "\n",
    "def print_output(output):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "    from contextlib import redirect_stdout\n",
    "    \n",
    "    code = 'print(\"\".join({}))'.format(output)\n",
    "    f = StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        exec(code)\n",
    "        out_value = f.getvalue()\n",
    "    \n",
    "    return out_value\n",
    "\n",
    "def save_generation(prompt_id, prompt, code, output):\n",
    "    db = Database()\n",
    "    gen_data = {'prompt_id': prompt_id, 'prompt': prompt, 'code': code, 'output': output}\n",
    "    db.insert_or_update_gen(kernel_id, version, gen_data)\n",
    "    \n",
    "def save_task_1step(step_id, out):\n",
    "    import json\n",
    "    t = json.loads(out)\n",
    "    key = list(t.keys())[0]\n",
    "    t = t[key]\n",
    "    if t.get('column_names'):\n",
    "        t['column names'] = t['column_names']\n",
    "    column_names = t['column names']\n",
    "    if not isinstance(column_names, list):\n",
    "        if 'all' in column_names.lower():\n",
    "            column_names = 'All'\n",
    "        column_names = [column_names]\n",
    "        t['column names'] = column_names\n",
    "    \n",
    "    db = Database()\n",
    "    task = {'Step': step_id, \n",
    "                 'Task Name': t['name'], \n",
    "                 'Column Names': ','.join(t['column names']),\n",
    "                 'Method': t['strategy'],\n",
    "                 'Reason': t['reason']\n",
    "                }\n",
    "    db.insert_or_update_task(kernel_id, version, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "e5b42466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(prompt_content, prompt_id=0):\n",
    "    promptlist_len = prompt_list_len(prompt_list)\n",
    "    if method == 2:\n",
    "        code, output = read_code(prompt_list, max(0, promptlist_len-1))\n",
    "        code += '\\n----------\\n'\n",
    "        output += '\\n----------\\n'\n",
    "    elif method == 1:\n",
    "        code = read_codev1(prompt_list, prompt_id-1)\n",
    "        #output = read_output_from_nb(nb_file, prompt_list, prompt_id-1)\n",
    "        #output += '\\n----------\\n'\n",
    "        #output = 'Output:\\n' + output\n",
    "        output = ''\n",
    "\n",
    "    # add datafile and data metadata to prompt content (at the first time)\n",
    "    if promptlist_len == 0:\n",
    "        prompt_content += \"@datafile\"\n",
    "    # get prompt support information\n",
    "    prompt_content, prompt_support = prompt_preprocessing(prompt_content)\n",
    "\n",
    "    # create prompt for chatgpt\n",
    "    #prompt = prompt_support + '\\n' + code + '\\n' + output + '\\n' + instruction + prompt_content + ans\n",
    "    if method == 2:\n",
    "        prompt = code + prompt_support + '\\n' + instruction + prompt_content + ans\n",
    "    elif method == 1:\n",
    "        prompt = prompt_support + '\\n' + instruction + prompt_content + ans + code\n",
    "    print(prompt)\n",
    "\n",
    "    # call openai\n",
    "    out = response(openai_key, prompt, temperature=0.2)\n",
    "    out = out.replace('<code>', '').strip()\n",
    "    print('>>', out)\n",
    "    \n",
    "    # save code generation (no output)\n",
    "    save_generation(prompt_id, prompt_content, out, '')\n",
    "\n",
    "    # execute code\n",
    "    if method == 2:\n",
    "        out_value, error = exec_code(out)\n",
    "        print(error, out_value)\n",
    "        # update prompt list\n",
    "        update_prompt(prompt_list, prompt_id, instruction, problem, ans, prompt_content, out, out_value)\n",
    "    \n",
    "    \n",
    "    if method == 1:\n",
    "        # update prompt list\n",
    "        out_value = ''\n",
    "        update_prompt(prompt_list, prompt_id, instruction, problem, ans, prompt_content, out, out_value)\n",
    "        # get the full code\n",
    "        #code = read_codev1(prompt_list, prompt_id+1)\n",
    "        #out_value, error = exec_code(code)\n",
    "        #print(error, out_value)\n",
    "        # update prompt list\n",
    "        update_prompt(prompt_list, prompt_id, instruction, problem, ans, prompt_content, out, out_value)\n",
    "        # write code\n",
    "        write_code(nb_file, prompt_list, prompt_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "62e849c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_steps(prompt_content, show_output=True, show_code=True, step_id=None):\n",
    "    if not step_id:\n",
    "        step_id = prompt_list_len(prompt_list)\n",
    "        print('step_id', step_id)\n",
    "    prompt_id = max(0, step_id-1)\n",
    "    if method == 2:\n",
    "        code, output = read_code(prompt_list, prompt_id)\n",
    "        code += '\\n----------\\n'\n",
    "        output += '\\n----------\\n'\n",
    "    elif method == 1:\n",
    "        '''code = read_codev1(prompt_list, max(0, prompt_id))\n",
    "        code += '\\n----------\\n'\n",
    "        _, output = read_code(prompt_list, max(0, prompt_id-1))\n",
    "        output += '\\n----------\\n'\n",
    "        '''\n",
    "        #code = read_codev1(prompt_list, max(0, prompt_id))\n",
    "        output = read_output_from_nb(nb_file, prompt_list, prompt_id)\n",
    "        # update output generation\n",
    "        save_generation(prompt_id, prompt_list[prompt_id]['prompt'], prompt_list[prompt_id]['generated_code'], output)\n",
    "        \n",
    "        code = read_codev1(prompt_list, prompt_id)\n",
    "        code += '\\n----------\\n'\n",
    "        output += '\\n----------\\n'\n",
    "        \n",
    "\n",
    "    # get prompt support information\n",
    "    prompt_content, prompt_support = prompt_preprocessing(prompt_content)\n",
    "    \n",
    "    code = 'Previous Code:\\n' + code\n",
    "    output = 'Previous Output:\\n' + output\n",
    "    if show_code == False:\n",
    "        code = ''\n",
    "    if show_output == False:\n",
    "        output = ''\n",
    "        \n",
    "    # create prompt for chatgpt\n",
    "    #prompt =  output + prompt_support + '\\n' + prompt_content\n",
    "    prompt = code + output + prompt_content\n",
    "    print(prompt)\n",
    "\n",
    "    # call openai\n",
    "    out = response(openai_key, prompt, temperature=0.7)\n",
    "    print('>>', out)\n",
    "    \n",
    "    # save task\n",
    "    save_task_1step(step_id, out)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "d7c86e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "Data file name: earthquake_data.csv.\n",
      "\n",
      "You are the python code generation for a data science problem.\n",
      "Please generate the next code after \"A: <code>\"\n",
      "Load data from file. Show data information and few rows.\n",
      "A:\n",
      "<code>\n",
      "\n",
      ">> import pandas as pd\n",
      "\n",
      "# Load data from file\n",
      "data = pd.read_csv(\"earthquake_data.csv\")\n",
      "\n",
      "# Show data information\n",
      "print(data.info())\n",
      "\n",
      "# Show few rows of data\n",
      "print(data.head())\n"
     ]
    }
   ],
   "source": [
    "data_file = 'earthquake_data.csv'\n",
    "nb_file = '../kaggle/kernels_train/adambyrne/earthquake-alert-classifier/workflow.ipynb'\n",
    "db = Database()\n",
    "kernel_id = db.get_kernel_by_ref('adambyrne/earthquake-alert-classifier')\n",
    "print(kernel_id)\n",
    "if kernel_id == 0:\n",
    "    raise \"Error\"\n",
    "prompt = 'Load data from file. Show data information and few rows.'\n",
    "prompt_id=0\n",
    "generate_code(prompt, prompt_id)\n",
    "# first task\n",
    "step_id=0\n",
    "out = '''{\n",
    "  \"step\": {\n",
    "    \"name\": \"Load data\",\n",
    "    \"column names\": [\"All\"],\n",
    "    \"strategy\": \"Load data from file. Show data information and few rows.\",\n",
    "    \"reason\": \"\"\n",
    "  }\n",
    "}'''\n",
    "save_task_1step(step_id, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "8e3cd157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_id 4\n",
      "Previous Code:\n",
      "import pandas as pd\n",
      "\n",
      "# Load data from file\n",
      "data = pd.read_csv(\"earthquake_data.csv\")\n",
      "\n",
      "# Show data information\n",
      "print(data.info())\n",
      "\n",
      "# Show few rows of data\n",
      "print(data.head())\n",
      "# Check for missing values in latitude and longitude columns\n",
      "missing_values = data[['latitude', 'longitude']].isnull().sum()\n",
      "print(\"Missing values in latitude and longitude columns:\")\n",
      "print(missing_values)\n",
      "\n",
      "# Import geopy library for geocoding\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "# Create geocoder object\n",
      "geolocator = Nominatim(user_agent=\"my_app\")\n",
      "\n",
      "# Function to get country from latitude and longitude\n",
      "def get_country(lat, lon):\n",
      "    location = geolocator.reverse((lat, lon), exactly_one=True)\n",
      "    if location is not None:\n",
      "        return location.raw['address'].get('country', None)\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "# Impute missing values in country column using latitude and longitude\n",
      "data['country'] = data.apply(lambda row: get_country(row['latitude'], row['longitude']) if pd.isnull(row['country']) else row['country'], axis=1)\n",
      "\n",
      "# Show updated data\n",
      "print(\"Updated data:\")\n",
      "print(data.head())\n",
      "# Fill missing values for continent: From the columns latitude and longitude to find the missing values by geodata for columns continent\n",
      "\n",
      "# Check for missing values in continent column\n",
      "missing_values = data['continent'].isnull().sum()\n",
      "print(\"Missing values in continent column:\")\n",
      "print(missing_values)\n",
      "\n",
      "# Function to get continent from latitude and longitude\n",
      "def get_continent(lat, lon):\n",
      "    location = geolocator.reverse((lat, lon), exactly_one=True)\n",
      "    if location is not None:\n",
      "        return location.raw['address'].get('continent', None)\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "# Impute missing values in continent column using latitude and longitude\n",
      "data['continent'] = data.apply(lambda row: get_continent(row['latitude'], row['longitude']) if pd.isnull(row['continent']) else row['continent'], axis=1)\n",
      "\n",
      "# Show updated data\n",
      "print(\"Updated data:\")\n",
      "print(data.head())\n",
      "# Remove Missing Values for Alert: Dropping rows for columns alert\n",
      "\n",
      "# Check for missing values in alert column\n",
      "missing_values = data['alert'].isnull().sum()\n",
      "print(\"Missing values in alert column:\")\n",
      "print(missing_values)\n",
      "\n",
      "# Drop rows with missing values in alert column\n",
      "data = data.dropna(subset=['alert'])\n",
      "\n",
      "# Show updated data\n",
      "print(\"Updated data:\")\n",
      "print(data.head())\n",
      "\n",
      "----------\n",
      "Previous Output:\n",
      "Missing values in alert column:\n",
      "367\n",
      "Updated data:\n",
      "                                          title  magnitude         date_time  \\\n",
      "0  M 7.0 - 18 km SW of Malango, Solomon Islands        7.0  22-11-2022 02:03   \n",
      "1      M 6.9 - 204 km SW of Bengkulu, Indonesia        6.9  18-11-2022 13:37   \n",
      "2                                      M 7.0 -         7.0  12-11-2022 07:09   \n",
      "3           M 7.3 - 205 km ESE of Neiafu, Tonga        7.3  11-11-2022 10:48   \n",
      "4                                      M 6.6 -         6.6  09-11-2022 10:14   \n",
      "\n",
      "   cdi  mmi  alert  tsunami  sig net  nst   dmin   gap magType    depth  \\\n",
      "0    8    7  green        1  768  us  117  0.509  17.0     mww   14.000   \n",
      "1    4    4  green        0  735  us   99  2.229  34.0     mww   25.000   \n",
      "2    3    3  green        1  755  us  147  3.125  18.0     mww  579.000   \n",
      "3    5    5  green        1  833  us  149  1.865  21.0     mww   37.000   \n",
      "4    0    2  green        1  670  us  131  4.998  27.0     mww  624.464   \n",
      "\n",
      "   latitude  longitude                  location continent          country  \n",
      "0   -9.7963    159.596  Malango, Solomon Islands   Oceania  Solomon Islands  \n",
      "1   -4.9559    100.738       Bengkulu, Indonesia      None             None  \n",
      "2  -20.0508   -178.346                       NaN   Oceania             Fiji  \n",
      "3  -19.2918   -172.129             Neiafu, Tonga      None             None  \n",
      "4  -25.5948    178.278                       NaN      None             None  \n",
      "\n",
      "\n",
      "----------\n",
      "The problem is earthquake alert classification. You are an expert in earthquake domain. Based on the problem, the dataset, previous code, previous output, list 1 new method to fill missing value for country in the following json format: step {name, column names, strategy, reason}.\n",
      ">> {\n",
      "  \"step\": {\n",
      "    \"name\": \"Fill Missing Values for Country\",\n",
      "    \"column names\": [\"country\"],\n",
      "    \"strategy\": \"Using geocoding with geopy library\",\n",
      "    \"reason\": \"To impute missing values in the country column based on latitude and longitude coordinates\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The problem is earthquake alert classification. You are an expert in earthquake domain. Based on the problem, the dataset, previous code, previous output, \"\\\n",
    "\"list 1 new method to fill missing value for country in the following json format: step {name, column names, strategy, reason}.\"\\\n",
    "#\" The previous output shows no missing values.\"\n",
    "task = generate_steps(prompt, show_output=True, show_code=True, step_id=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "27481649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remove Missing Values for Alert: Dropping rows for columns alert'"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "t = json.loads(task)\n",
    "key = list(t.keys())[0]\n",
    "t = t[key]\n",
    "if t.get('column_names'):\n",
    "    t['column names'] = t['column_names']\n",
    "column_names = t['column names']\n",
    "if not isinstance(column_names, list):\n",
    "    column_names = [column_names]\n",
    "    t['column names'] = column_names\n",
    "#t['strategy'] = 'From the columns latitude and longitude to find the missing values by geodata'\n",
    "p = '{}: {} for columns {}'.format(t['name'], t['strategy'], ', '.join(t['column names']))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c274e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"The problem is house price prediction. Based on the problem, previous code, previous output, \"\\\n",
    "\"list All necessary steps for data preparation in the following json format: step {name, strategy, reason}\"\n",
    "tasks = generate_steps(prompt, show_output=True, show_code=True, step_id=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "t = json.loads(tasks)\n",
    "steps = t['steps']\n",
    "for s in steps:\n",
    "    if s.get('column_names'):\n",
    "        s['column names'] = s['column_names']\n",
    "    p = '{}: {} for columns {}'.format(s['name'], s['strategy'], ', '.join(s['column names']))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "2647f398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are the python code generation for a data science problem.\n",
      "Please generate the next code after \"A: <code>\"\n",
      "Remove Missing Values for Alert: Dropping rows for columns alert\n",
      "A:\n",
      "<code>\n",
      "import pandas as pd\n",
      "\n",
      "# Load data from file\n",
      "data = pd.read_csv(\"earthquake_data.csv\")\n",
      "\n",
      "# Show data information\n",
      "print(data.info())\n",
      "\n",
      "# Show few rows of data\n",
      "print(data.head())\n",
      "# Check for missing values in latitude and longitude columns\n",
      "missing_values = data[['latitude', 'longitude']].isnull().sum()\n",
      "print(\"Missing values in latitude and longitude columns:\")\n",
      "print(missing_values)\n",
      "\n",
      "# Import geopy library for geocoding\n",
      "from geopy.geocoders import Nominatim\n",
      "\n",
      "# Create geocoder object\n",
      "geolocator = Nominatim(user_agent=\"my_app\")\n",
      "\n",
      "# Function to get country from latitude and longitude\n",
      "def get_country(lat, lon):\n",
      "    location = geolocator.reverse((lat, lon), exactly_one=True)\n",
      "    if location is not None:\n",
      "        return location.raw['address'].get('country', None)\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "# Impute missing values in country column using latitude and longitude\n",
      "data['country'] = data.apply(lambda row: get_country(row['latitude'], row['longitude']) if pd.isnull(row['country']) else row['country'], axis=1)\n",
      "\n",
      "# Show updated data\n",
      "print(\"Updated data:\")\n",
      "print(data.head())\n",
      "# Fill missing values for continent: From the columns latitude and longitude to find the missing values by geodata for columns continent\n",
      "\n",
      "# Check for missing values in continent column\n",
      "missing_values = data['continent'].isnull().sum()\n",
      "print(\"Missing values in continent column:\")\n",
      "print(missing_values)\n",
      "\n",
      "# Function to get continent from latitude and longitude\n",
      "def get_continent(lat, lon):\n",
      "    location = geolocator.reverse((lat, lon), exactly_one=True)\n",
      "    if location is not None:\n",
      "        return location.raw['address'].get('continent', None)\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "# Impute missing values in continent column using latitude and longitude\n",
      "data['continent'] = data.apply(lambda row: get_continent(row['latitude'], row['longitude']) if pd.isnull(row['continent']) else row['continent'], axis=1)\n",
      "\n",
      "# Show updated data\n",
      "print(\"Updated data:\")\n",
      "print(data.head())\n",
      "\n",
      ">> # Remove Missing Values for Alert: Dropping rows for columns alert\n",
      "\n",
      "# Check for missing values in alert column\n",
      "missing_values = data['alert'].isnull().sum()\n",
      "print(\"Missing values in alert column:\")\n",
      "print(missing_values)\n",
      "\n",
      "# Drop rows with missing values in alert column\n",
      "data = data.dropna(subset=['alert'])\n",
      "\n",
      "# Show updated data\n",
      "print(\"Updated data:\")\n",
      "print(data.head())\n"
     ]
    }
   ],
   "source": [
    "#prompt = \"Model Training: Train a regression model using the selected features for columns gestation, height, weight, smoke. Use R2 score\"\n",
    "prompt_id = 3\n",
    "generate_code(p, prompt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "bab84830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_id 8\n"
     ]
    }
   ],
   "source": [
    "step_id = prompt_list_len(prompt_list)\n",
    "print('step_id', step_id)\n",
    "prompt_id = max(0, step_id-1)\n",
    "if method == 2:\n",
    "    code, output = read_code(prompt_list, prompt_id)\n",
    "    code += '\\n----------\\n'\n",
    "    output += '\\n----------\\n'\n",
    "elif method == 1:\n",
    "    output = read_output_from_nb(nb_file, prompt_list, prompt_id)\n",
    "    # update output generation\n",
    "    save_generation(prompt_id, prompt_list[prompt_id]['prompt'], prompt_list[prompt_id]['generated_code'], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bee7e30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'You are the python code generation for a data science problem.\\n',\n",
       " 'problem': 'Problem Description:\\n',\n",
       " 'ans': '\\nA:\\n<code>\\n',\n",
       " 'prompt': 'Check for missing values',\n",
       " 'generated_code': '# Check for missing values\\nprint(data.isnull().sum())\\n',\n",
       " 'output': '\\nYear                          0\\nMake                          0\\nModel                         0\\nCondition                     0\\nPrice                         0\\nConsumer_Rating               0\\nConsumer_Review_#             0\\nExterior_Color               11\\nInterior_Color               11\\nDrivetrain                   11\\nMPG                        1485\\nFuel_Type                    11\\nTransmission                 11\\nEngine                       11\\nVIN                          11\\nStock_#                      11\\nMileage                      11\\nComfort_Rating              552\\nInterior_Design_Rating      552\\nPerformance_Rating          552\\nValue_For_Money_Rating      552\\nExterior_Styling_Rating     552\\nReliability_Rating          552\\nState                        73\\nSeller_Type                  73\\ndtype: int64\\n'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_list[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
