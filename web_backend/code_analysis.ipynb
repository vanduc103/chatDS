{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced6e6c9",
   "metadata": {},
   "source": [
    "## Analyze the kaggle code and extract to code blocks with step name, columns, methods and reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3e86a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "116574a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from config import upload_folder, allowed_extensions, open_api_mode, jupyter_url, openai_key\n",
    "from utils import read_code, response, update_prompt, prompt_list_len, read_codev1, read_output_from_nb, write_code\n",
    "\n",
    "# show unlimited pandas\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# show unlimited numpy\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# do not show backtrace in python error\n",
    "import sys\n",
    "sys.tracebacklimit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ae66957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(output):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "    from contextlib import redirect_stdout\n",
    "    \n",
    "    code = 'print(\"\".join({}))'.format(output)\n",
    "    f = StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        exec(code)\n",
    "        out_value = f.getvalue()\n",
    "    \n",
    "    return out_value\n",
    "\n",
    "def print_output2(output):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "    from contextlib import redirect_stdout\n",
    "    \n",
    "    code = 'print(f\"{}\")'.format(output)\n",
    "    print(code)\n",
    "    f = StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        exec(code)\n",
    "        out_value = f.getvalue()\n",
    "    \n",
    "    return out_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1433c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pydb\n",
    "class Database:\n",
    "    def __init__(self):\n",
    "        host = \"localhost\"\n",
    "        port = 5432\n",
    "        user = \"musicadmin\"\n",
    "        password = \"gsds2023#\"\n",
    "        dbname = \"promptdb\"\n",
    "        self.con = pydb.connect(host=host, port=port, user=user, password=password, database=dbname)\n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "    def close(self):\n",
    "        self.cur.close()\n",
    "        self.con.close()\n",
    "\n",
    "    \"\"\"\n",
    "    for code table\n",
    "    \"\"\"\n",
    "    def list_codes(self):\n",
    "        self.cur.execute(\"SELECT c.*, k.ref AS kernel_ref, d.ref AS dataset_ref FROM codes as c INNER JOIN kernels as k ON c.kernel_id = k.id INNER JOIN datasets d ON k.dataset_id = d.id ORDER BY c.id\")\n",
    "        result = self.cur.fetchall()\n",
    "        self.close()\n",
    "        return result\n",
    "    \n",
    "    def list_codes_by_kernel(self, kernel_id):\n",
    "        self.cur.execute(\"SELECT c.*, k.ref AS kernel_ref, d.ref AS dataset_ref FROM codes as c INNER JOIN kernels as k ON c.kernel_id = k.id INNER JOIN datasets d ON k.dataset_id = d.id WHERE c.kernel_id=%s ORDER BY c.id\", (kernel_id,))\n",
    "        result = self.cur.fetchall()\n",
    "        self.close()\n",
    "        return result\n",
    "    \n",
    "    def list_kernels_from_codes(self):\n",
    "        self.cur.execute(\"SELECT DISTINCT k.id, k.ref FROM codes as c INNER JOIN kernels as k ON c.kernel_id = k.id ORDER BY k.id\")\n",
    "        result = self.cur.fetchall()\n",
    "        self.close()\n",
    "        return result\n",
    "    \n",
    "    \"\"\"\n",
    "    for workflow table\n",
    "    \"\"\"\n",
    "    def list_workflow(self):\n",
    "        self.cur.execute(\"SELECT k.ref AS kernel, w.* FROM workflow as w INNER JOIN kernels as k ON w.kernel_id = k.id ORDER BY w.step\")\n",
    "        result = self.cur.fetchall()\n",
    "        self.close()\n",
    "        return result\n",
    "    \n",
    "    def list_workflow_by_kernel(self, kernel_id):\n",
    "        self.cur.execute(\"SELECT k.ref AS kernel, w.* FROM workflow as w INNER JOIN kernels as k ON w.kernel_id = k.id WHERE w.kernel_id=%s ORDER BY w.step\", (kernel_id,))\n",
    "        result = self.cur.fetchall()\n",
    "        self.close()\n",
    "        return result\n",
    "    \n",
    "    def insert_workflow(self, kernel_id, workflow):\n",
    "        # check kernel_id\n",
    "        self.cur.execute(\"SELECT id FROM kernels WHERE id = %s\", (kernel_id,))\n",
    "        result = self.cur.fetchall()\n",
    "        if result and len(result) > 0:\n",
    "            # build data with kernel_id\n",
    "            data = []\n",
    "            for task in workflow:\n",
    "                step = task['Step']\n",
    "                task_name = task['Task Name']\n",
    "                column_names = task['Column Names']\n",
    "                method = task['Method']\n",
    "                reason = task['Reason']\n",
    "                data.append((kernel_id, step, task_name, column_names, method, reason))\n",
    "            # insert code\n",
    "            self.cur.executemany(\"INSERT INTO workflow(kernel_id, step, task_name, column_names, method, reason) VALUES (%s, %s, %s, %s, %s, %s)\", data)\n",
    "            self.con.commit()\n",
    "            self.close()\n",
    "            return self.cur.rowcount\n",
    "        else:\n",
    "            print('Kernel {} does not exist!'.format(kernel_id))\n",
    "            return 0\n",
    "\n",
    "    # insert generation by batch\n",
    "    def insert_gen(self, kernel_id, gen_data):\n",
    "        # check kernel_id\n",
    "        self.cur.execute(\"SELECT id FROM kernels WHERE id = %s\", (kernel_id,))\n",
    "        result = self.cur.fetchall()\n",
    "        if result and len(result) > 0:\n",
    "            version = 0\n",
    "            # build data with kernel_id\n",
    "            data = []\n",
    "            for d in gen_data:\n",
    "                step = d['step']\n",
    "                prompt = d['prompt']\n",
    "                code = d['code']\n",
    "                output = d['output']\n",
    "                data.append((kernel_id, version, step, prompt, code, output))\n",
    "            # insert code\n",
    "            self.cur.executemany(\"INSERT INTO generation(kernel_id, version, step, prompt, code, output) VALUES (%s, %s, %s, %s, %s, %s)\", data)\n",
    "            self.con.commit()\n",
    "            self.close()\n",
    "            return self.cur.rowcount\n",
    "        else:\n",
    "            print('Kernel {} does not exist!'.format(kernel_id))\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "50aa18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_steps(problem, code):\n",
    "    # create prompt for chatgpt\n",
    "    prompt_content = 'From the problem description, summarize the given code in the following json format: step {name, column names, strategy, reason}.'\n",
    "    code += '\\n---------------\\n'\n",
    "    if len(problem) > 0:\n",
    "        problem = 'Problem Description: ' + problem + '\\n'\n",
    "    prompt = code + problem + prompt_content\n",
    "    print(prompt)\n",
    "\n",
    "    # call openai\n",
    "    out = response(openai_key, prompt, temperature=0.7)\n",
    "    print('>>', out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fd169ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3278"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = Database()\n",
    "codes = db.list_codes()\n",
    "len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d8237c71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "sns.barplot(data=df1,x='number of bathrooms',y='Price')\n",
      "\n",
      "plt.figure(figsize=(12,18))\n",
      "sns.countplot(data=df1,y='Built Year')\n",
      "plt.show()\n",
      "\n",
      "plt.figure(figsize=(12,18))\n",
      "sns.countplot(data=df1,y='Postal Code')\n",
      "plt.show()\n",
      "\n",
      "df1=df1.drop(['id'],axis=1)\n",
      "\n",
      "df1=df1.drop(['Postal Code'],axis=1)\n",
      "\n",
      "plt.figure(figsize=(15,15))\n",
      "sns.heatmap(df1.corr(),linewidths=0.5,annot=True,cmap='Blues')\n",
      "plt.show()\n",
      "\n",
      "df1=df1.drop(['lot area','condition of the house','Built Year','lot_area_renov','Number of schools nearby','Distance from the airport','Longitude'],axis=1)\n",
      "\n",
      "from sklearn.model_selection import train_test_split \n",
      "X=df1.drop(['Price'],axis =1)\n",
      "y=df1['Price']\n",
      "\n",
      "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=11)\n",
      "\n",
      "pipelines = {\n",
      "    'en':make_pipeline(StandardScaler(), ElasticNet()),\n",
      "    'lasso':make_pipeline(StandardScaler(), Lasso()),\n",
      "    'Rcv':make_pipeline(StandardScaler(), RidgeCV()),\n",
      "    'CatB':make_pipeline(StandardScaler(), CatBoostRegressor(eval_metric='RMSE',verbose=1000)),\n",
      "    'lr':make_pipeline(StandardScaler(), LinearRegression()),\n",
      "    'rf':make_pipeline(StandardScaler(), RandomForestRegressor()),\n",
      "    'gb':make_pipeline(StandardScaler(), GradientBoostingRegressor()),\n",
      "    'dtc':make_pipeline(StandardScaler(),DecisionTreeRegressor()),\n",
      "    'xg':make_pipeline(StandardScaler(),XGBRegressor())\n",
      "}\n",
      "\n",
      "fit_models = {}\n",
      "for algo, pipeline in pipelines.items():\n",
      "    model = pipeline.fit(X_train, y_train)\n",
      "    fit_models[algo] = model\n",
      "\n",
      "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
      "maes=[]\n",
      "al=[]\n",
      "for algo, model in fit_models.items():\n",
      "    yhat = model.predict(X_test)\n",
      "    al.append(algo)\n",
      "    maes.append(mean_squared_error(y_test,yhat)**0.5)\n",
      "    print(algo,'MEAN ABSOLUTE ERROR', mean_absolute_error(y_test,yhat))\n",
      "    print(algo,'ROOT MEAN SQUARED ERROR',mean_squared_error(y_test,yhat)**0.5)\n",
      "\n",
      "CatB = CatBoostRegressor(verbose=1000,eval_metric='RMSE')\n",
      "rf = RandomForestRegressor()\n",
      "gb = GradientBoostingRegressor()\n",
      "xg = XGBRegressor()\n",
      "lr=LinearRegression()\n",
      "\n",
      "stregr = StackingRegressor(estimators=[('catb',CatB),('xg', xg),('gb',gb)],\n",
      "                           final_estimator=lr)\n",
      "\n",
      "pipeline = make_pipeline(\n",
      "    StandardScaler(),\n",
      "    stregr\n",
      ")\n",
      "pipeline.fit(X_train, y_train)\n",
      "\n",
      "# Generate predictions on the test set\n",
      "y_pred = pipeline.predict(X_test)\n",
      "\n",
      "# Evaluate the model\n",
      "print(\"Root Mean Squared Error: %.4f\" % mean_squared_error(y_test,y_pred)**0.5)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------\n",
      "Problem Description: House price prediction in India.\n",
      "From the problem description, summarize the given code in the following json format: step {name, column names, strategy, reason}.\n",
      ">> {\n",
      "  \"step1\": {\n",
      "    \"name\": \"Data Visualization\",\n",
      "    \"column names\": [\"number of bathrooms\", \"Price\"],\n",
      "    \"strategy\": \"Bar plot\",\n",
      "    \"reason\": \"To visualize the relationship between the number of bathrooms and the price of houses.\"\n",
      "  },\n",
      "  \"step2\": {\n",
      "    \"name\": \"Data Visualization\",\n",
      "    \"column names\": [\"Built Year\"],\n",
      "    \"strategy\": \"Count plot\",\n",
      "    \"reason\": \"To visualize the distribution of houses based on their built year.\"\n",
      "  },\n",
      "  \"step3\": {\n",
      "    \"name\": \"Data Visualization\",\n",
      "    \"column names\": [\"Postal Code\"],\n",
      "    \"strategy\": \"Count plot\",\n",
      "    \"reason\": \"To visualize the distribution of houses based on their postal code.\"\n",
      "  },\n",
      "  \"step4\": {\n",
      "    \"name\": \"Data Preprocessing\",\n",
      "    \"column names\": [\"id\"],\n",
      "    \"strategy\": \"Drop column\",\n",
      "    \"reason\": \"To remove the 'id' column which is not relevant for the house price prediction.\"\n",
      "  },\n",
      "  \"step5\": {\n",
      "    \"name\": \"Data Preprocessing\",\n",
      "    \"column names\": [\"Postal Code\"],\n",
      "    \"strategy\": \"Drop column\",\n",
      "    \"reason\": \"To remove the 'Postal Code' column which is not relevant for the house price prediction.\"\n",
      "  },\n",
      "  \"step6\": {\n",
      "    \"name\": \"Data Visualization\",\n",
      "    \"column names\": [\"Correlation matrix\"],\n",
      "    \"strategy\": \"Heatmap\",\n",
      "    \"reason\": \"To visualize the correlation between different numerical features in the dataset.\"\n",
      "  },\n",
      "  \"step7\": {\n",
      "    \"name\": \"Data Preprocessing\",\n",
      "    \"column names\": [\"lot area\", \"condition of the house\", \"Built Year\", \"lot_area_renov\", \"Number of schools nearby\", \"Distance from the airport\", \"Longitude\"],\n",
      "    \"strategy\": \"Drop columns\",\n",
      "    \"reason\": \"To remove the columns which are not relevant or have low correlation with the target variable.\"\n",
      "  },\n",
      "  \"step8\": {\n",
      "    \"name\": \"Data Splitting\",\n",
      "    \"column names\": [\"Price\"],\n",
      "    \"strategy\": \"Train-test split\",\n",
      "    \"reason\": \"To divide the dataset into training and testing sets for model training and evaluation.\"\n",
      "  },\n",
      "  \"step9\": {\n",
      "    \"name\": \"Model Training\",\n",
      "    \"column names\": [\"Price\"],\n",
      "    \"strategy\": \"Various regression models\",\n",
      "    \"reason\": \"To train and evaluate different regression models on the training data.\"\n",
      "  },\n",
      "  \"step10\": {\n",
      "    \"name\": \"Model Evaluation\",\n",
      "    \"column names\": [\"Price\"],\n",
      "    \"strategy\": \"Mean Absolute Error, Root Mean Squared Error\",\n",
      "    \"reason\": \"To evaluate the performance of different regression models based on the prediction errors.\"\n",
      "  },\n",
      "  \"step11\": {\n",
      "    \"name\": \"Model Training\",\n",
      "    \"column names\": [\"Price\"],\n",
      "    \"strategy\": \"Stacking Regressor\",\n",
      "    \"reason\": \"To train a stacking ensemble model using the best performing regression models.\"\n",
      "  },\n",
      "  \"step12\": {\n",
      "    \"name\": \"Model Evaluation\",\n",
      "    \"column names\": [\"Price\"],\n",
      "    \"strategy\": \"Root Mean Squared Error\",\n",
      "    \"reason\": \"To evaluate the performance of the stacking ensemble model on the test data.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "kernel_id = 51\n",
    "codes = db.list_codes_by_kernel(kernel_id)\n",
    "print(len(codes))\n",
    "\n",
    "problem = 'House price prediction in India.'\n",
    "all_steps = []\n",
    "begin_idx = 15\n",
    "batch = 15\n",
    "end_idx = min(begin_idx + batch, len(codes))\n",
    "while begin_idx < len(codes):\n",
    "    part_codes = codes[begin_idx:end_idx]\n",
    "    code = [c[2] + '\\n' for c in part_codes]\n",
    "    code = print_output(code)\n",
    "\n",
    "    steps = generate_steps(problem, code)\n",
    "    all_steps.append(steps)\n",
    "    \n",
    "    begin_idx = end_idx\n",
    "    end_idx = min(begin_idx + batch, len(codes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b7b173bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step1': {'name': 'Data Visualization',\n",
       "  'column names': ['number of bathrooms', 'Price'],\n",
       "  'strategy': 'Bar plot',\n",
       "  'reason': 'To visualize the relationship between the number of bathrooms and the price of houses.'},\n",
       " 'step2': {'name': 'Data Visualization',\n",
       "  'column names': ['Built Year'],\n",
       "  'strategy': 'Count plot',\n",
       "  'reason': 'To visualize the distribution of houses based on their built year.'},\n",
       " 'step3': {'name': 'Data Visualization',\n",
       "  'column names': ['Postal Code'],\n",
       "  'strategy': 'Count plot',\n",
       "  'reason': 'To visualize the distribution of houses based on their postal code.'},\n",
       " 'step4': {'name': 'Data Preprocessing',\n",
       "  'column names': ['id'],\n",
       "  'strategy': 'Drop column',\n",
       "  'reason': \"To remove the 'id' column which is not relevant for the house price prediction.\"},\n",
       " 'step5': {'name': 'Data Preprocessing',\n",
       "  'column names': ['Postal Code'],\n",
       "  'strategy': 'Drop column',\n",
       "  'reason': \"To remove the 'Postal Code' column which is not relevant for the house price prediction.\"},\n",
       " 'step6': {'name': 'Data Visualization',\n",
       "  'column names': ['Correlation matrix'],\n",
       "  'strategy': 'Heatmap',\n",
       "  'reason': 'To visualize the correlation between different numerical features in the dataset.'},\n",
       " 'step7': {'name': 'Data Preprocessing',\n",
       "  'column names': ['lot area',\n",
       "   'condition of the house',\n",
       "   'Built Year',\n",
       "   'lot_area_renov',\n",
       "   'Number of schools nearby',\n",
       "   'Distance from the airport',\n",
       "   'Longitude'],\n",
       "  'strategy': 'Drop columns',\n",
       "  'reason': 'To remove the columns which are not relevant or have low correlation with the target variable.'},\n",
       " 'step8': {'name': 'Data Splitting',\n",
       "  'column names': ['Price'],\n",
       "  'strategy': 'Train-test split',\n",
       "  'reason': 'To divide the dataset into training and testing sets for model training and evaluation.'},\n",
       " 'step9': {'name': 'Model Training',\n",
       "  'column names': ['Price'],\n",
       "  'strategy': 'Various regression models',\n",
       "  'reason': 'To train and evaluate different regression models on the training data.'},\n",
       " 'step10': {'name': 'Model Evaluation',\n",
       "  'column names': ['Price'],\n",
       "  'strategy': 'Mean Absolute Error, Root Mean Squared Error',\n",
       "  'reason': 'To evaluate the performance of different regression models based on the prediction errors.'},\n",
       " 'step11': {'name': 'Model Training',\n",
       "  'column names': ['Price'],\n",
       "  'strategy': 'Stacking Regressor',\n",
       "  'reason': 'To train a stacking ensemble model using the best performing regression models.'},\n",
       " 'step12': {'name': 'Model Evaluation',\n",
       "  'column names': ['Price'],\n",
       "  'strategy': 'Root Mean Squared Error',\n",
       "  'reason': 'To evaluate the performance of the stacking ensemble model on the test data.'}}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "#step_json = json.loads('[' + all_steps[0] + ']')\n",
    "step_json = json.loads(all_steps[0])\n",
    "step_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "24ee0c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Step': 11,\n",
       "  'Task Name': 'Data Visualization',\n",
       "  'Column Names': 'number of bathrooms,Price',\n",
       "  'Method': 'Bar plot',\n",
       "  'Reason': 'To visualize the relationship between the number of bathrooms and the price of houses.'},\n",
       " {'Step': 12,\n",
       "  'Task Name': 'Data Visualization',\n",
       "  'Column Names': 'Built Year',\n",
       "  'Method': 'Count plot',\n",
       "  'Reason': 'To visualize the distribution of houses based on their built year.'},\n",
       " {'Step': 13,\n",
       "  'Task Name': 'Data Visualization',\n",
       "  'Column Names': 'Postal Code',\n",
       "  'Method': 'Count plot',\n",
       "  'Reason': 'To visualize the distribution of houses based on their postal code.'},\n",
       " {'Step': 14,\n",
       "  'Task Name': 'Data Preprocessing',\n",
       "  'Column Names': 'id',\n",
       "  'Method': 'Drop column',\n",
       "  'Reason': \"To remove the 'id' column which is not relevant for the house price prediction.\"},\n",
       " {'Step': 15,\n",
       "  'Task Name': 'Data Preprocessing',\n",
       "  'Column Names': 'Postal Code',\n",
       "  'Method': 'Drop column',\n",
       "  'Reason': \"To remove the 'Postal Code' column which is not relevant for the house price prediction.\"},\n",
       " {'Step': 16,\n",
       "  'Task Name': 'Data Visualization',\n",
       "  'Column Names': 'Correlation matrix',\n",
       "  'Method': 'Heatmap',\n",
       "  'Reason': 'To visualize the correlation between different numerical features in the dataset.'},\n",
       " {'Step': 17,\n",
       "  'Task Name': 'Data Preprocessing',\n",
       "  'Column Names': 'lot area,condition of the house,Built Year,lot_area_renov,Number of schools nearby,Distance from the airport,Longitude',\n",
       "  'Method': 'Drop columns',\n",
       "  'Reason': 'To remove the columns which are not relevant or have low correlation with the target variable.'},\n",
       " {'Step': 18,\n",
       "  'Task Name': 'Data Splitting',\n",
       "  'Column Names': 'Price',\n",
       "  'Method': 'Train-test split',\n",
       "  'Reason': 'To divide the dataset into training and testing sets for model training and evaluation.'},\n",
       " {'Step': 19,\n",
       "  'Task Name': 'Model Training',\n",
       "  'Column Names': 'Price',\n",
       "  'Method': 'Various regression models',\n",
       "  'Reason': 'To train and evaluate different regression models on the training data.'},\n",
       " {'Step': 20,\n",
       "  'Task Name': 'Model Evaluation',\n",
       "  'Column Names': 'Price',\n",
       "  'Method': 'Mean Absolute Error, Root Mean Squared Error',\n",
       "  'Reason': 'To evaluate the performance of different regression models based on the prediction errors.'},\n",
       " {'Step': 21,\n",
       "  'Task Name': 'Model Training',\n",
       "  'Column Names': 'Price',\n",
       "  'Method': 'Stacking Regressor',\n",
       "  'Reason': 'To train a stacking ensemble model using the best performing regression models.'},\n",
       " {'Step': 22,\n",
       "  'Task Name': 'Model Evaluation',\n",
       "  'Column Names': 'Price',\n",
       "  'Method': 'Root Mean Squared Error',\n",
       "  'Reason': 'To evaluate the performance of the stacking ensemble model on the test data.'}]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "workflow = []\n",
    "target_column = 'Price'\n",
    "pass_keys = ''\n",
    "stepidx = 10\n",
    "for k in step_json.keys():\n",
    "    if k in pass_keys:\n",
    "        continue\n",
    "    step = step_json[k]\n",
    "    stepidx += 1\n",
    "    task_name = step['Name'.lower()]\n",
    "    if step.get('Column_Names'.lower()):\n",
    "        column_names = step['Column_Names'.lower()]\n",
    "    else:\n",
    "        column_names = step['Column Names'.lower()]\n",
    "    if isinstance(column_names, list):\n",
    "        column_names = ','.join(column_names)\n",
    "    else:\n",
    "        column_names = column_names.replace(' and ', ',')\n",
    "        column_names = column_names.replace(\"'\", \"\").replace('\"','')\n",
    "    #print(column_names)\n",
    "    # check task name\n",
    "    pattern = r\"(load|read)\"\n",
    "    if re.search(pattern, task_name, re.IGNORECASE):\n",
    "        column_names = 'All'\n",
    "    #pattern = r\"(train|test|validate|evaluation|evaluate)\"\n",
    "    #if re.search(pattern, task_name, re.IGNORECASE):\n",
    "    #    column_names = target_column\n",
    "        \n",
    "    if 'All' in column_names:\n",
    "        column_names = 'All'\n",
    "    elif len(column_names) == 0:\n",
    "        column_names = 'All'\n",
    "    elif 'N/A' in column_names:\n",
    "        column_names = 'All'\n",
    "    method = step['Strategy'.lower()]\n",
    "    reason = step['Reason'.lower()]\n",
    "    \n",
    "    task = {'Step': stepidx, 'Task Name': task_name, 'Column Names': column_names, 'Method': method, 'Reason': reason}\n",
    "    workflow.append(task)\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "87c3959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 12 row(s)\n"
     ]
    }
   ],
   "source": [
    "# insert workflow\n",
    "rowcnt = 0\n",
    "db = Database()\n",
    "rowcnt += db.insert_workflow(kernel_id, workflow)\n",
    "print('Inserted {} row(s)'.format(rowcnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a9902ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import print_str\n",
    "\n",
    "# read prompt, code, output from nb_file\n",
    "prompts = []\n",
    "codes = []\n",
    "outputs = []\n",
    "\n",
    "nb_file = \"../kaggle/kernels_train/abrish2003/house-rent-eda-along-with-price-prediction/house-rent-eda-along-with-price-prediction.ipynb\"\n",
    "\n",
    "nb_code = json.load(open(nb_file))\n",
    "nb_cells = nb_code['cells']\n",
    "for cell_idx in range(len(nb_cells)):\n",
    "    cell = nb_cells[cell_idx]\n",
    "    if cell['cell_type'] == 'markdown' and '-' in cell['source'][0]:\n",
    "        prompt = cell['source'][0].replace('-', '').strip()\n",
    "        code_cell = nb_cells[cell_idx + 1]\n",
    "        if code_cell['cell_type'] == 'code':\n",
    "            code = code_cell['source']\n",
    "            code = print_str(code)\n",
    "            output = ''\n",
    "            for out in code_cell['outputs']:\n",
    "                if out.get('name') == 'stdout' and out.get('output_type') == 'stream':\n",
    "                    output = out['text']\n",
    "                    output = print_str(output)\n",
    "                    break\n",
    "            prompts.append(prompt)\n",
    "            codes.append(code)\n",
    "            outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "33c98618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = Database()\n",
    "gen_data = []\n",
    "for i in range(len(prompts)):\n",
    "    gen_data.append({'step':i, 'prompt':prompts[i], 'code': codes[i], 'output': outputs[i]})\n",
    "db.insert_gen(kernel_id, gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3fbec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
